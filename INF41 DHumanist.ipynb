{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [INF41] DH Humanist Mail Archive \n",
    "\n",
    "##Text mining brouillon \n",
    "\n",
    "Ressources utiles pour le projet : \n",
    "    \n",
    "* Enron mail dataset https://www.kaggle.com/stephensebastin/topic-modeling-enron-email-dataset-updated (topic modeling) et https://www.kaggle.com/jamestollefson/enron-network-analysis (réseau)\n",
    "\n",
    "* Exploring the Music Library Association Mailing List: A TextMining Approach http://kahyunchoi.com/papers/ismir2017_xhu.pdf\n",
    "        \n",
    "* Latent Dirichlet Allocation https://radimrehurek.com/gensim/models/ldamodel.html   \n",
    "    \n",
    "* Topic Modeling Genre: An Exploration of French Classical and Enlightenment Drama (Topic modeling mais avec MALLET en java) http://www.digitalhumanities.org/dhq/vol/11/2/000291/000291.html \n",
    "    \n",
    "* http://voyant.tools.huma-num.fr/\n",
    "    \n",
    "* David Blei et une de ces publications introductives : Probabilistic Topic Models, Communications of the ACM, Volume 55 Issue 4, pp. 77-84, 2012.\n",
    "\n",
    "* Cours de Julien Velcin sur la fouille de texte  et http://mediamining.univ-lyon2.fr/velcin/public/TM/introduction.pdf & http://mediamining.univ-lyon2.fr/velcin/public/HN/intro_fouilledetextes.pdf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A des fins de test, ce brouillon utilise l'archive humanist.2007-2008.txt' (Converted Text bien plus lisible) dispo ici http://dhhumanist.org/Archives/Converted_Text/ \n",
    "(étude en généralisation à prévoir)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup des bibliothèques nécessaires en vrac dsl\n",
    "#manipulation des données regex etc...\n",
    "import pandas as pd\n",
    "import os, sys, email,re\n",
    "import os.path\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "\n",
    "# Plotting et visualisation \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_style('whitegrid')\n",
    "# fail to import wordcloud ???\n",
    "\n",
    "#nlp et corpus\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from subprocess import check_output\n",
    "\n",
    "# algos : clustering TF-IDF, LDA et PCa\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "# études en réseau \n",
    "import networkx as nx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#chargement des données brutes nomenclature des variables h=humanist ct=convertedtext 0708=années\n",
    "with open(\"C://Users//henry//AnacondaProjects//humanist//humanist.2007-2008.txt\", 'r', encoding='ANSI') as hct0708:\n",
    "    hct0708 = [line.strip() for line in hct0708.readlines()]\n",
    "vectorizer = CountVectorizer( encoding='utf-8', max_df=1, stop_words='english')\n",
    "vectorizer.fit(hct0708)\n",
    "#liste des features \n",
    "vocab = vectorizer.get_feature_names()\n",
    "#vocabulaire vectorisé\n",
    "vv = vectorizer.vocabulary_\n",
    "\n",
    "#mis en commentaire pour plus de lisibilité\n",
    "#type(vv)\n",
    "#len(vv)\n",
    "#print(vv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de regex pour récupérer des éléments du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-63-bfc4013766bc>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-63-bfc4013766bc>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    #   print(line)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# récupération des adresses mails dans le corpus avec une re\n",
    "for line in hct0708 :\n",
    "    if re.findall(r'[\\w\\.-]+@[\\w\\.-]+(\\.[\\w]+)+',line):\n",
    "        # commenté pour alléger le notebook\n",
    "     #   print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-108-105f873d84ec>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-108-105f873d84ec>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    #X-Humanist:\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "with open(\"C://Users//henry//AnacondaProjects//humanist//humanist.2007-2008.txt\", 'r', encoding='ANSI') as hct0708:\n",
    "    hct0708 = [line.strip() for line in hct0708.readlines()]\n",
    "for line in hct0708 :\n",
    "    if re.search(r'Subject:\\s+(.*)',line):\n",
    "    #commenté pour alléger le notebook\n",
    "    #print(line)\n",
    "#    Il est possble d'utiliser une regex similaire pour les en-tetes suivants \n",
    "#re.search(r'From:\\s+(.*)',line):\n",
    "#Subject: Humanist's 20th\n",
    "#Date: \n",
    "#X-Humanist: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAD0CAYAAACLiB96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c7533f15f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#peu pertinant de dessiner le plot du vocabulaire à ce stade là \n",
    "D = vv\n",
    "plt.barh(range(len(D)), D.values(), align='center')\n",
    "plt.xticks(range(len(D)), list(D.keys()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9180)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_bag_of_words = vectorizer.transform(hct0708).toarray()\n",
    "lines_bag_of_words.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(lowercase=False, stop_words='english' )\n",
    "tfidf_vectorizer.fit(hct0708)\n",
    "# commenté pour alléger le notebook\n",
    "#tfidf_vectorizer.vocabulary_ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_tfidf_feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-6457182ed811>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtop_tfidf_feats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtop_mean_feats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_hct0708\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_hct0708\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-113-6457182ed811>\u001b[0m in \u001b[0;36mtop_mean_feats\u001b[1;34m(Xtr, features, grp_ids, min_tfidf, top_n)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;34m''' D[D < min_tfidf] = 0 '''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtfidf_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtop_tfidf_feats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtop_mean_feats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_hct0708\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_hct0708\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_tfidf_feats' is not defined"
     ]
    }
   ],
   "source": [
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "  #  ''' Return the top n features that on average are most important amongst documents in rows\n",
    "#     indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "    ''' D[D < min_tfidf] = 0 '''\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n",
    "\n",
    "top_mean_feats(X_hct0708, features_hct0708)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En complément de Count vectorizer, utilisation de TfidfVectorizer. TFxIDF (term frequency-inverse document frequency) permet d’évaluer l’importance des mots dans ce corpus. (plus le mot sera fréquent, plus son poids sera élevé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des mots les plus fréquents (selon TFxIDF) :\n",
    "X_hct0708 = tfidf_vectorizer.transform(hct0708)\n",
    "features_hct0708 = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "D_tf = X_hct0708.toarray()\n",
    "tf_sum = np.sum(D_tf, axis=0)\n",
    "top_tfidf_feats(tf_sum, features_hct0708)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation du formalisme sac de mots pour déterminer la forme du corpus. On peut maintenant construire la matrice documents * termes : à l’aide de ce sac. Ne disposant pas de catégories nous ne pouvons pas appliquer d’apprentissage supervisé Pour déterminer quel algorithme appliquer, j’ai fait appel à cette carte.http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html Pour ce type de données, le clustering semble plus indiqué : cela va permettre d’utiliser la distance euclidienne pour grouper les mots les plus proches les uns des autres dans notre corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termes les plus fréquents par clusters\n",
      "Cluster 0:\n",
      " http\n",
      " www\n",
      " href\n",
      " org\n",
      " uk\n",
      " ac\n",
      " edu\n",
      " com\n",
      " html\n",
      " kcl\n",
      "Cluster 1:\n",
      " Vol\n",
      " Num\n",
      " Humanist\n",
      " 21\n",
      " 22\n",
      " 429\n",
      " 261\n",
      " No\n",
      " 45\n",
      " Brook\n",
      "Cluster 2:\n",
      " Computing\n",
      " Humanities\n",
      " Willard\n",
      " McCarty\n",
      " London\n",
      " King\n",
      " College\n",
      " Centre\n",
      " mccarty_at_kcl\n",
      " willard\n",
      "Cluster 3:\n",
      " development\n",
      " support\n",
      " services\n",
      " software\n",
      " research\n",
      " technical\n",
      " digital\n",
      " The\n",
      " projects\n",
      " use\n",
      "Cluster 4:\n",
      " following\n",
      " topics\n",
      " areas\n",
      " message\n",
      " The\n",
      " include\n",
      " range\n",
      " research\n",
      " invited\n",
      " sections\n",
      "Cluster 5:\n",
      " new\n",
      " work\n",
      " data\n",
      " researchers\n",
      " media\n",
      " The\n",
      " digital\n",
      " research\n",
      " humanities\n",
      " field\n",
      "Cluster 6:\n",
      " The\n",
      " University\n",
      " Subject\n",
      " 2008\n",
      " From\n",
      " research\n",
      " Digital\n",
      " 2007\n",
      " information\n",
      " conference\n",
      "Cluster 7:\n",
      " Date\n",
      " 2007\n",
      " 0100\n",
      " 06\n",
      " 0000\n",
      " Wed\n",
      " Tue\n",
      " 08\n",
      " 07\n",
      " 09\n"
     ]
    }
   ],
   "source": [
    "clustering = KMeans(n_clusters=8, init='k-means++', max_iter=1000, n_init=1)\n",
    "clustering.fit(X_hct0708)\n",
    "#nous souhaitons affichcher les clusters avec les termes les plus proches les uns des autres dans les titres\n",
    "print(\"Termes les plus fréquents par clusters\")\n",
    "centroides = clustering.cluster_centers_.argsort()[:, ::-1]\n",
    "termes = features_hct0708\n",
    "for i in range(8):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in centroides[i, :10]:\n",
    "        print(' %s' % termes[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "* les regex pourront nous servir pour extraire les informations liées aux sujets, expéditeurs des mails ou àccéder à des chaines de caractères si besoin. \n",
    "* les analyse par _Vector Space model_ et le clustering par Kmeans sont inexploitables  : le besoin de stopwords personnalisés se fait sentir. \n",
    "* pour la suite  Modèle probabiliste avec Allocation de Dirichlet Latente  plus adaptée ? [en cours] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tentative de LDA .... \n",
    "#id2word = gensim.corpora.Dictionary.load_from_text(hct0708)\n",
    "#lda = gensim.models.ldamodel.LdaModel(corpus=X_hct0708, id2word=id2word, num_topics=10, update_every=0, passes=200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
